<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Need a hand? - lavafroth</title><meta name=description content='The tides
Over the past few months, a sizable fraction of my developer peers have taken to AI tools. Beckoned from under a rock by the light of day, I was taken aback by this rising wave of vibe coding.
They claim AI tools to be phenomenal for frontend technologies like React and NextJS. The selling point? Context aware autocompletes and agent mode.
Context aware autocompletes happen when the model watches your code so it can suggest autocompletes while you code.'><meta name=author content><link rel="preload stylesheet" as=style href=https://lavafroth.is-a.dev/app.min.css><link rel=preload as=image href=../../header.svg><link as=font href=https://lavafroth.is-a.dev/latinmodern-math.otf><link rel=preload as=image href=https://lavafroth.is-a.dev/github.svg><link rel=preload as=image href=https://lavafroth.is-a.dev/about.svg><link rel=preload as=image href=https://lavafroth.is-a.dev/art.svg><link rel=icon href=https://lavafroth.is-a.dev/favicon.png><link rel=blog-icon href=https://lavafroth.is-a.dev/icon.png></head><body data-menu=true><header class=header><h1><a class=site-name href=https://lavafroth.is-a.dev/><svg viewBox="0 0 8790 2400"><path d="M80 1935V465h216v1270h286v2e2zm853 0 222-1470h264l222 1470h-210l-40-3e2h-208l-40 3e2zm280-528h148l-62-494-6-78h-12l-6 78zm1025 528L2014 465h210l108 868 8 142h12l8-142 108-868h210l-224 1470zm813 0 222-1470h264l222 1470h-210l-40-3e2h-208l-40 3e2zm280-528h148l-62-494-6-78h-12l-6 78zm851 528V465h514v222h-298v386h2e2v222h-2e2v640zm910 0V465h216q194 0 286 108 92 107 92 316 0 124-43 215-44 90-106 132l147 699h-216l-122-620h-38v620zm216-820q60 0 95-26 35-27 50-76t15-116q0-105-34-161-35-57-126-57zm1084 836q-90 0-154-42-65-42-99-114-35-72-35-162V767q0-91 35-162 34-72 99-114 64-42 154-42t155 42q64 42 99 114 34 72 34 162v866q0 90-34 162-35 72-99 114-65 42-155 42zm0-210q40 0 56-33 16-34 16-75V767q0-41-17-74-17-34-55-34-37 0-54 34-18 33-18 74v866q0 41 17 75 17 33 55 33zm890 194V687h-204V465h624v222h-204v1248zm828 0V465h216v608h168V465h216v1470h-216v-640h-168v640z"/></svg></a></h1><div class=push></div><a style=--url:url(./github.svg) href=https://github.com/lavafroth aria-label=github target=_blank></a><a href=../../about/ aria-label=about style=--url:url(./about.svg)></a><a href=../../art/ aria-label=art style=--url:url(./art.svg)></a></header><main class=main><article class=post-single data-pagefind-body><header class=post-title><p data-pagefind-ignore><time>Apr 3, 2025 | 4 minutes read</time></p><h1 data-pagefind-meta=title>Need a hand?</h1></header><section class=post-content><h1 id=the-tides>The tides</h1><p>Over the past few months, a sizable fraction of my developer peers have taken to AI tools. Beckoned from under a rock by the light of day, I was taken aback by this rising wave of <em>vibe coding</em>.</p><p>They claim AI tools to be phenomenal for frontend technologies like React and NextJS. The selling point? Context aware autocompletes and agent mode.</p><p>Context aware autocompletes happen when the model watches your code so it can suggest autocompletes while you code.</p><p>Agent mode involves an <em>&ldquo;autonomous agent&rdquo;</em> based on a prompt that can manipulate files, run commands and essentially carve out a project.</p><h1 id=impressionable>Impressionable</h1><p>When I ask my friends about how LLMs improve their code, it is often simple, easy to spot errors that would have been obvious by reading the documentation. Thus, the LLMs really provide us an artificial sense of competence.</p><p>Here&rsquo;s what my friend @noobscience had to say:</p><blockquote><p>The place where it helps me the most is simple errors. Like, let&rsquo;s say I forgot to await a promise, it pretty much finds that out.</p></blockquote><p>A good first question is &ldquo;what is the scope of a Copilot?&rdquo; Is the purpose simply to write boilerplate code and small fixes?</p><p>Most reasonable developers would not want to surrender the steering wheel completely to the LLM because of their unpredictability. Good luck trying to fix bugs with little to no clue about how your own code works.</p><h1 id=a-cheap-knock-off>A cheap knock-off</h1><p>A deeper question concerns the tooling used during development.</p><p>When most people admit that they use LLMs to catch small mistakes and fix them predictably, what they actually mean is that these models serve as cheap, less predictable knock-offs of more robust, deterministic and less resource hungry language tooling.</p><p>Developers needing LLMs assistance is a symptom of the compiler or language tooling being subpar. That they are not good enough to catch low hanging errors.</p><p>In fact, quite a few languages provide fantastic tooling and make programming feel incredibly pleasant. Some good examples include <code>gopls</code> for the Go programming language and <code>rust-analyzer</code> for Rust.</p><p>To conclude, I think what developers really want are crude, simple yet battle tested tooling instead of big blobs that take three nukes&rsquo; worth of energy to train and 4 GPUs to run.</p><hr><p>Update: 2025-06-15</p><h1 id=thicc-macros>Thicc macros</h1><p>After pondering on the status quo for a couple days, I have come to consider AI code as thick, probabilistic macros. Their drawbacks surface when they eventually output poor quality code.</p><p>I do like the idea of having comments that describe the steps to a problem and having code generated for it, by a human or otherwise. I tried to distill the idea of such code retrieval and after putting a lot of thought into its architecture, I&rsquo;m happy to announce Silos.</p><h1 id=silos>Silos</h1><p>Silos is a simple server that runs a small embedding model to embed queries, find the top <span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span> matches and respond with the output in JSON. You can give it a try <a href=https://github.com/lavafroth/silos>here</a>.</p><p>Here&rsquo;s how it differs from LLMs</p><ul><li>Snippets are the building blocks: Silos ingests and stores snippets, each with an associated description and language.</li><li>Absence of context: You are on your own, snippet queried must be small and as self-contained as possible. While it allows placeholders for variables, it does not hyperspecialize the code for your codebase.</li><li>Runs on ancient hardware: Silos v1 uses all-MiniLM for embedding queries, it&rsquo;s a fairly small model with a memory footprint of 50MiB.</li><li>Local first: One can easily setup Silos on local machines for offline work. I do plan to host a central repository and API for community snippets.</li><li>Code, your way: Don&rsquo;t like the code style of the existing snippets? Feel free to add your own! You can add custom snippets using the REST API ephemerally or add them to the snippets directory for persistent use.</li></ul><h2 id=fun-fact>Fun fact</h2><p>Before public development, the project was named SnippetHub. Considering all the other <abbr title><em>hubs</em></abbr> around, I switched it up to be Silos because the snippets are in self-contained silos.</p></section></article><footer class=post-tags data-pagefind-meta=tags><a href=https://lavafroth.is-a.dev/tags/llm class=list-tag>LLM</a>
<a href=https://lavafroth.is-a.dev/tags/ai class=list-tag>AI</a>
<a href=https://lavafroth.is-a.dev/tags/rant class=list-tag>Rant</a>
<a href=https://lavafroth.is-a.dev/tags/copilot class=list-tag>Copilot</a></footer><nav class=post-nav><a class=prev href=https://lavafroth.is-a.dev/post/detecting-stripped-go-binaries/><span>←</span><span>Easy grep to detect stripped Go binaries</span></a>
<a class=next href=https://lavafroth.is-a.dev/post/in-search-of-the-smallest-dna-compl/><span>In search of the smallest DNA complement function</span><span>→</span></a></nav></main><footer class=footer><p>&copy; 2025 <a href=https://lavafroth.is-a.dev/>lavafroth</a></p><p><a href=https://github.com/lavafroth/lavafroth.github.io/issues/new/choose>Report an issue</a></p><p><a href=https://github.com/lavafroth/lavafroth.github.io/discussions/>Discuss</a></p><p><a href=https://lavafroth.is-a.dev/privacy>Privacy</a></p><p><a href=https://creativecommons.org/licenses/by-sa/4.0/legalcode>License</a></p></footer></body></html>